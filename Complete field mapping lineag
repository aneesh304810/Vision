"""
========================================================
COMPLETE FIELD MAPPING TOOL - FIXED VERSION
========================================================
Maps three source systems to AddVantage:
1. Entity Models ‚Üí AddVantage
2. SEI Fields ‚Üí AddVantage

Features:
- Fixed "View Details" navigation
- Handles "Metadata" sheet for AddVantage
- Handles "All Feeds" sheet for SEI
- Semantic matching for both
- All fields kept (matched + unmatched)
========================================================
"""

import streamlit as st
import pandas as pd
import numpy as np

# Import modules
import entity_explorer as ee
import field_mapping_viewer as fmv
import complete_lineage_viewer as clv

# ML
try:
    from sentence_transformers import SentenceTransformer
    ML_AVAILABLE = True
except:
    ML_AVAILABLE = False

# Viz
try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except:
    PLOTLY_AVAILABLE = False

# ========================================================
# UTILITY FUNCTIONS
# ========================================================

def clean_column_name(col):
    """Clean column names for consistent access"""
    return str(col).strip().lower().replace(" ", "_").replace("/", "_").replace("-", "_").replace("(", "").replace(")", "").strip("_")

def safe_get(row, column, default=""):
    """Safely get value from row"""
    try:
        val = row.get(column, default) if isinstance(row, dict) else getattr(row, column, default)
        return val if pd.notna(val) and str(val) != 'nan' and str(val) != '' else default
    except:
        return default

def normalize_text(text):
    """Normalize text for matching"""
    if not isinstance(text, str):
        return ""
    return text.lower().replace("_", "").replace(" ", "").replace("-", "").strip()

# ========================================================
# CONFIG
# ========================================================

st.set_page_config(
    page_title="Field Mapping Tool",
    page_icon="üîÑ",
    layout="wide"
)

# ========================================================
# SESSION STATE
# ========================================================

if 'entity_matrix_df' not in st.session_state:
    st.session_state.entity_matrix_df = None
if 'entity_models' not in st.session_state:
    st.session_state.entity_models = {}
if 'addvantage_df' not in st.session_state:
    st.session_state.addvantage_df = None
if 'sei_df' not in st.session_state:
    st.session_state.sei_df = None
if 'matched_entity_addv' not in st.session_state:
    st.session_state.matched_entity_addv = None
if 'matched_sei_addv' not in st.session_state:
    st.session_state.matched_sei_addv = None
if 'selected_entity' not in st.session_state:
    st.session_state.selected_entity = None
if 'complete_lineage_df' not in st.session_state:
    st.session_state.complete_lineage_df = None

# ========================================================
# SEI LOADER
# ========================================================

def load_sei_mapping(file):
    """
    Load SEI field mapping from "All Feeds" sheet
    
    Columns expected:
    - Metadata (interface name)
    - Feed (section)
    - Position
    - Field Name
    - Field Description
    - Data Type
    - Nullable
    - Reference
    """
    
    st.info("üìä Loading SEI Field Mapping...")
    
    try:
        excel_file = pd.ExcelFile(file)
        sheets = excel_file.sheet_names
        
        st.write(f"üìã Found sheets: {', '.join(sheets)}")
        
        # Find "All Feeds" sheet
        sheet_name = None
        for name in ["All Feeds", "all feeds", "All feeds", "ALL FEEDS", "AllFeeds"]:
            if name in sheets:
                sheet_name = name
                break
        
        if not sheet_name:
            sheet_name = sheets[0]
            st.warning(f"‚ö†Ô∏è 'All Feeds' not found. Using: {sheet_name}")
        else:
            st.success(f"‚úÖ Using sheet: {sheet_name}")
        
        # Load
        df = pd.read_excel(file, sheet_name=sheet_name)
        
        st.write(f"Loaded {len(df)} rows")
        
        # Clean columns
        df.columns = [clean_column_name(col) for col in df.columns]
        
        with st.expander("üìã Column Mapping", expanded=False):
            st.write("Detected columns:", list(df.columns))
            st.dataframe(df.head(3))
        
        # Standardize column names
        rename_map = {}
        for col in df.columns:
            if 'metadata' in col or 'interface' in col:
                rename_map[col] = 'interface_name'
            elif 'feed' in col and 'metadata' not in col:
                rename_map[col] = 'feed_section'
            elif 'position' in col:
                rename_map[col] = 'position'
            elif 'field' in col and 'name' in col:
                rename_map[col] = 'field_name'
            elif 'description' in col:
                rename_map[col] = 'field_description'
            elif 'data' in col and 'type' in col:
                rename_map[col] = 'data_type'
            elif 'null' in col:
                rename_map[col] = 'nullable'
            elif 'ref' in col:
                rename_map[col] = 'reference'
        
        df = df.rename(columns=rename_map)
        
        # Clean data
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].astype(str).str.strip().replace({'nan': '', 'None': ''})
        
        # Remove header rows
        if 'field_name' in df.columns:
            df = df[~df['field_name'].str.contains('Header Record', case=False, na=False)]
            df = df[df['field_name'] != '']
        
        # Remove empty rows
        df = df.dropna(how='all')
        
        st.success(f"‚úÖ **Loaded {len(df)} SEI fields**")
        
        # Show summary by interface
        if 'interface_name' in df.columns:
            interface_counts = df['interface_name'].value_counts()
            with st.expander("üìä Fields by Interface", expanded=False):
                for interface, count in interface_counts.head(10).items():
                    st.write(f"- {interface}: {count} fields")
        
        return df
        
    except Exception as e:
        st.error(f"‚ùå Error loading SEI: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None

# ========================================================
# MATCH SEI TO ADDVANTAGE
# ========================================================

def match_sei_to_addvantage(sei_df, addv_df, entity_models=None, min_score=60, use_semantic=True):
    """
    Match SEI fields to AddVantage fields using multilingual-e5-large
    Optimized for 8GB NVIDIA GPU (Blackwell architecture)
    """
    
    st.info("üîÑ Starting SEI ‚Üí AddVantage matching...")
    
    # Initialize semantic model for GPU if enabled
    model = None
    sei_emb_name = None
    sei_emb_desc = None
    addv_emb = None
    
    if use_semantic:
        try:
            import torch
            from sentence_transformers import SentenceTransformer
            
            st.info("üöÄ Initializing multilingual-e5-large on NVIDIA GPU...")
            
            # Check GPU availability
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                st.success(f"‚úÖ GPU Detected: {gpu_name} ({gpu_memory:.1f} GB)")
            else:
                st.warning("‚ö†Ô∏è No GPU detected, falling back to CPU")
            
            # Load multilingual-e5-large optimized for GPU
            model = SentenceTransformer(
                'intfloat/multilingual-e5-large',
                device='cuda' if torch.cuda.is_available() else 'cpu'
            )
            
            # Enable GPU optimizations for Blackwell
            if torch.cuda.is_available():
                # Use mixed precision for 8GB VRAM optimization
                model.half()  # FP16 for faster inference and lower memory
                
                # Enable CUDA optimizations
                torch.backends.cudnn.benchmark = True
                torch.backends.cuda.matmul.allow_tf32 = True
                
                st.success("‚úÖ Model loaded with FP16 precision for 8GB GPU optimization")
            else:
                st.info("‚ÑπÔ∏è Running on CPU (slower)")
            
            # SEI: Create embeddings for field names
            st.info("üìä Creating SEI field name embeddings...")
            sei_texts_name = []
            for _, sei_row in sei_df.iterrows():
                field_name = safe_get(sei_row, 'field_name', '')
                # E5 models require "query: " prefix for better performance
                sei_texts_name.append(f"query: {field_name}")
            
            # Encode with GPU acceleration (batch processing for efficiency)
            with torch.cuda.amp.autocast():  # Automatic mixed precision
                sei_emb_name = model.encode(
                    sei_texts_name,
                    batch_size=64,  # Larger batch for GPU
                    show_progress_bar=True,
                    convert_to_numpy=True,
                    normalize_embeddings=True  # L2 normalization for better similarity
                )
            
            st.success(f"‚úÖ SEI field name embeddings created: {sei_emb_name.shape}")
            
            # SEI: Create embeddings for field names + descriptions
            st.info("üìä Creating SEI enhanced embeddings (name + description)...")
            sei_texts_desc = []
            for _, sei_row in sei_df.iterrows():
                field_name = safe_get(sei_row, 'field_name', '')
                field_desc = safe_get(sei_row, 'field_description', '')
                combined = f"query: {field_name} {field_desc}".strip()
                sei_texts_desc.append(combined)
            
            with torch.cuda.amp.autocast():
                sei_emb_desc = model.encode(
                    sei_texts_desc,
                    batch_size=64,
                    show_progress_bar=True,
                    convert_to_numpy=True,
                    normalize_embeddings=True
                )
            
            st.success(f"‚úÖ SEI enhanced embeddings created: {sei_emb_desc.shape}")
            
            # AddVantage: Build enhanced embeddings using entity descriptions
            st.info("üìä Enhancing AddVantage fields with entity model descriptions...")
            addv_texts_enhanced = []
            addv_field_to_entity_desc = {}
            enhanced_count = 0
            
            for _, addv_row in addv_df.iterrows():
                addv_field = safe_get(addv_row, 'field_name', '')
                
                # Try to find entity description for this field
                entity_desc = ''
                if entity_models:
                    for entity_name, entity_df in entity_models.items():
                        source_col = None
                        desc_col = None
                        
                        for col in entity_df.columns:
                            col_lower = col.lower()
                            if not source_col and 'source' in col_lower and 'field' in col_lower:
                                source_col = col
                            if not desc_col and col_lower == 'field_description':
                                desc_col = col
                        
                        if source_col and desc_col:
                            # EXACT MATCH ONLY to avoid wrong descriptions
                            for _, entity_row in entity_df.iterrows():
                                entity_field = safe_get(entity_row, source_col, '')
                                if entity_field and normalize_text(entity_field) == normalize_text(addv_field):
                                    entity_desc = safe_get(entity_row, desc_col, '')
                                    if entity_desc:
                                        addv_field_to_entity_desc[addv_field] = {
                                            'description': entity_desc,
                                            'entity': entity_name
                                        }
                                        enhanced_count += 1
                                        break
                        
                        if entity_desc:
                            break
                
                # E5 models use "passage: " prefix for documents
                if entity_desc:
                    combined = f"passage: {addv_field} {entity_desc}".strip()
                else:
                    combined = f"passage: {addv_field}"
                
                addv_texts_enhanced.append(combined)
            
            if enhanced_count > 0:
                st.success(f"‚úÖ Enhanced {enhanced_count} AddVantage fields with entity descriptions")
                with st.expander("üìã Sample enhanced fields", expanded=False):
                    for field, info in list(addv_field_to_entity_desc.items())[:5]:
                        st.write(f"**{field}** (from {info['entity']}): {info['description'][:100]}...")
            else:
                st.warning("‚ö†Ô∏è No 'Field Description' column found in entity models")
            
            # Encode AddVantage embeddings with GPU
            st.info("üìä Creating AddVantage embeddings...")
            with torch.cuda.amp.autocast():
                addv_emb = model.encode(
                    addv_texts_enhanced,
                    batch_size=64,
                    show_progress_bar=True,
                    convert_to_numpy=True,
                    normalize_embeddings=True
                )
            
            st.success(f"‚úÖ AddVantage embeddings created: {addv_emb.shape}")
            
            # Clear GPU cache to free memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            st.success("‚úÖ All embeddings ready (multilingual-e5-large on GPU)")
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è GPU embedding failed: {e}")
            st.info("Falling back to CPU...")
            sei_emb_name = None
            sei_emb_desc = None
            use_semantic = False
    
    # Match each SEI field
    results = []
    progress = st.progress(0)
    status = st.empty()
    
    total = len(sei_df)
    matched = 0
    
    for idx, (_, sei_row) in enumerate(sei_df.iterrows()):
        if idx % 50 == 0:
            progress.progress((idx + 1) / total)
            status.text(f"Processing {idx + 1}/{total}... ({matched} matched)")
        
        sei_field = safe_get(sei_row, 'field_name', '')
        sei_desc = safe_get(sei_row, 'field_description', '')
        sei_norm = normalize_text(sei_field)
        
        best_idx = None
        best_score = 0
        best_match_type = ""
        
        # Find best match in AddVantage
        for aidx, (_, addv_row) in enumerate(addv_df.iterrows()):
            addv_field = safe_get(addv_row, 'field_name', '')
            addv_norm = normalize_text(addv_field)
            
            score = 0
            match_type = ""
            
            # 1. Exact field name match (HIGHEST PRIORITY - unbeatable)
            if sei_norm == addv_norm:
                score = 100
                match_type = "Exact name"
            
            # 2. Partial field name match (STRICTER - suffix only)
            elif not score and (addv_norm.endswith(sei_norm) or sei_norm.endswith(addv_norm)):
                if len(sei_norm) >= 3 and len(addv_norm) >= 3:
                    score = 75
                    match_type = "Partial name (suffix)"
            
            # 3. Semantic match using field name only (multilingual-e5-large)
            if not score and use_semantic and sei_emb_name is not None:
                try:
                    # Cosine similarity (already normalized, so just dot product)
                    sim_name = np.dot(sei_emb_name[idx], addv_emb[aidx])
                    
                    # E5 models produce better similarities, adjust thresholds
                    if sim_name >= 0.80:  # E5 threshold (was 0.85)
                        score = max(score, 90)
                        match_type = "Semantic name (high)"
                    elif sim_name >= 0.70:  # E5 threshold (was 0.75)
                        score = max(score, 75)
                        match_type = "Semantic name (med)"
                    elif sim_name >= 0.60:  # E5 threshold (was 0.65)
                        score = max(score, 65)
                        match_type = "Semantic name (low)"
                except:
                    pass
            
            # 4. Enhanced semantic match using field name + description (E5)
            if score < 100 and use_semantic and sei_emb_desc is not None and sei_desc:
                try:
                    sim_desc = np.dot(sei_emb_desc[idx], addv_emb[aidx])
                    
                    # E5 optimized thresholds
                    if sim_desc >= 0.75:  # E5 threshold (was 0.80)
                        boost_score = 95
                        if boost_score > score:
                            score = boost_score
                            match_type = "Semantic desc (high)"
                    elif sim_desc >= 0.65:  # E5 threshold (was 0.70)
                        boost_score = 85
                        if boost_score > score:
                            score = boost_score
                            match_type = "Semantic desc (med)"
                    elif sim_desc >= 0.55:  # E5 threshold (was 0.60)
                        boost_score = 70
                        if boost_score > score:
                            score = boost_score
                            match_type = "Semantic desc (low)"
                except:
                    pass
            
            # Track best match
            if score > best_score:
                best_score = score
                best_idx = aidx
                best_match_type = match_type
        
        # Build result - KEEP ALL
        row = sei_row.to_dict()
        
        if best_idx is not None and best_score >= min_score:
            matched += 1
            addv_match = addv_df.iloc[best_idx]
            addv_field_name = safe_get(addv_match, 'field_name')
            
            # Get AddVantage field description from entity model (EXACT MATCH ONLY)
            addv_field_desc = ''
            matched_entity_name = ''
            if entity_models and addv_field_name:
                for entity_name, entity_df in entity_models.items():
                    source_col = None
                    desc_col = None
                    
                    for col in entity_df.columns:
                        col_lower = col.lower()
                        if not source_col and 'source' in col_lower and 'field' in col_lower:
                            source_col = col
                        if not desc_col and col_lower == 'field_description':
                            desc_col = col
                    
                    if source_col and desc_col:
                        for _, entity_row in entity_df.iterrows():
                            entity_field = safe_get(entity_row, source_col, '')
                            # EXACT MATCH ONLY
                            if entity_field and normalize_text(entity_field) == normalize_text(addv_field_name):
                                addv_field_desc = safe_get(entity_row, desc_col, '')
                                matched_entity_name = entity_name
                                if addv_field_desc:
                                    break
                    
                    if addv_field_desc:
                        break
            
            row['matched_addv_field'] = addv_field_name
            row['matched_addv_description'] = addv_field_desc
            row['matched_addv_file'] = safe_get(addv_match, 'file_clean')
            row['matched_addv_type'] = safe_get(addv_match, 'data_type')
            row['matched_addv_length'] = safe_get(addv_match, 'max_length')
            row['match_score'] = best_score
            row['match_type'] = best_match_type
            row['match_confidence'] = 'High' if best_score >= 85 else 'Medium' if best_score >= 70 else 'Low'
        else:
            # Unmatched
            row['matched_addv_field'] = ''
            row['matched_addv_description'] = ''
            row['matched_addv_file'] = ''
            row['matched_addv_type'] = ''
            row['matched_addv_length'] = ''
            row['match_score'] = 0
            row['match_type'] = 'No match'
            row['match_confidence'] = 'Unmatched'
        
        results.append(row)
    
    progress.empty()
    status.empty()
    
    result_df = pd.DataFrame(results)
    
    unmatched = total - matched
    
    # Show GPU stats if available
    gpu_info = ""
    if use_semantic:
        try:
            import torch
            if torch.cuda.is_available():
                gpu_memory_used = torch.cuda.max_memory_allocated(0) / 1024**3
                gpu_info = f"\nüéÆ GPU Memory Used: {gpu_memory_used:.2f} GB"
        except:
            pass
    
    st.success(f"""
    ‚úÖ **SEI ‚Üí AddVantage Matching Complete!**
    
    üöÄ Model: multilingual-e5-large (GPU-accelerated)
    üìä Total SEI Fields: {total}
    ‚úÖ Matched: {matched} ({matched/total*100:.1f}%)
    ‚ùå Unmatched: {unmatched} ({unmatched/total*100:.1f}%)
    {gpu_info}
    
    ‚ö†Ô∏è All {total} fields kept in results (matched + unmatched)
    """)
    
    # Clear GPU memory
    if use_semantic:
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except:
            pass
    
    return result_df
    """
    Match SEI fields to AddVantage fields
    
    Enhanced matching using:
    1. Field names (exact/partial)
    2. Field descriptions (semantic)
    3. Entity model descriptions (if available)
    
    Keep ALL SEI fields even if unmatched
    """
    
    st.info("üîÑ Matching SEI ‚Üí AddVantage...")
    
    # Load multilingual-e5-large model if needed
    model = None
    if use_semantic and ML_AVAILABLE:
        try:
            import torch
            from sentence_transformers import SentenceTransformer
            
            st.write("üöÄ Loading multilingual-e5-large on NVIDIA GPU...")
            
            # Check GPU
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                st.success(f"‚úÖ GPU: {gpu_name} ({gpu_memory:.1f} GB)")
            
            # Load E5 model optimized for GPU
            model = SentenceTransformer(
                'intfloat/multilingual-e5-large',
                device='cuda' if torch.cuda.is_available() else 'cpu'
            )
            
            # GPU optimizations for 8GB VRAM
            if torch.cuda.is_available():
                model.half()  # FP16 precision
                torch.backends.cudnn.benchmark = True
                torch.backends.cuda.matmul.allow_tf32 = True
                st.success("‚úÖ Model loaded with FP16 optimization")
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Model load failed: {e}")
    
    # Build enhanced text for semantic matching
    # Combine field name + description for better context
    
    # Pre-compute embeddings with descriptions
    sei_emb_name = None
    sei_emb_desc = None
    addv_emb = None
    entity_emb = None
    
    if use_semantic and model:
        st.write("Computing embeddings with E5 model...")
        try:
            import torch
            
            # SEI: field name embeddings (with E5 query prefix)
            sei_texts_name = [f"query: {name}" for name in sei_df['field_name'].tolist()]
            
            with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.no_grad():
                sei_emb_name = model.encode(
                    sei_texts_name,
                    batch_size=64,
                    show_progress_bar=True,
                    convert_to_numpy=True,
                    normalize_embeddings=True
                )
            
            # SEI: field description embeddings (if available)
            if 'field_description' in sei_df.columns:
                sei_texts_desc = []
                for _, row in sei_df.iterrows():
                    field_name = safe_get(row, 'field_name', '')
                    field_desc = safe_get(row, 'field_description', '')
                    # E5 query prefix with combined context
                    combined = f"query: {field_name} {field_desc}".strip()
                    sei_texts_desc.append(combined)
                
                with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.no_grad():
                    sei_emb_desc = model.encode(
                        sei_texts_desc,
                        batch_size=64,
                        show_progress_bar=True,
                        convert_to_numpy=True,
                        normalize_embeddings=True
                    )
                
                st.success("‚úÖ SEI descriptions included in matching")
            
            # AddVantage: Build enhanced embeddings using entity descriptions
            # For each AddVantage field, find its entity description
            addv_texts_enhanced = []
            addv_field_to_entity_desc = {}
            
            for _, addv_row in addv_df.iterrows():
                addv_field = safe_get(addv_row, 'field_name', '')
                
                # Try to find this field in entity models to get its description
                entity_desc = ''
                if entity_models:
                    for entity_name, entity_df in entity_models.items():
                        source_col = None
                        desc_col = None
                        
                        # Look for specific column names
                        for col in entity_df.columns:
                            col_lower = col.lower()
                            # Source field column (various names)
                            if not source_col and 'source' in col_lower and 'field' in col_lower:
                                source_col = col
                            # Field Description column (specific name)
                            if not desc_col and col_lower == 'field_description':
                                desc_col = col
                        
                        # If we found both columns in this entity
                        if source_col and desc_col:
                            # EXACT MATCH ONLY - no partial to avoid wrong descriptions
                            for _, entity_row in entity_df.iterrows():
                                entity_field = safe_get(entity_row, source_col, '')
                                # Only exact match
                                if entity_field and normalize_text(entity_field) == normalize_text(addv_field):
                                    entity_desc = safe_get(entity_row, desc_col, '')
                                    if entity_desc:
                                        addv_field_to_entity_desc[addv_field] = {
                                            'description': entity_desc,
                                            'entity': entity_name
                                        }
                                        break
                        
                        if entity_desc:
                            break
                
                # E5 passage prefix for documents
                if entity_desc:
                    combined = f"passage: {addv_field} {entity_desc}".strip()
                else:
                    combined = f"passage: {addv_field}"
                
                addv_texts_enhanced.append(combined)
            
            # Encode enhanced AddVantage embeddings with GPU
            with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.no_grad():
                addv_emb = model.encode(
                    addv_texts_enhanced,
                    batch_size=64,
                    show_progress_bar=True,
                    convert_to_numpy=True,
                    normalize_embeddings=True
                )
            
            if addv_field_to_entity_desc:
                st.success(f"‚úÖ Enhanced {len(addv_field_to_entity_desc)} AddVantage fields with 'Field Description' from entity models")
                with st.expander("üìã Sample enhanced fields", expanded=False):
                    sample_count = min(5, len(addv_field_to_entity_desc))
                    for i, (field, info) in enumerate(list(addv_field_to_entity_desc.items())[:sample_count]):
                        st.write(f"**{field}** (from {info['entity']}): {info['description'][:100]}...")
            else:
                st.warning("‚ö†Ô∏è No 'Field Description' column found in entity models - using AddVantage field names only")
                st.info("üí° Make sure entity sheets have a column named 'Field Description'")
            
            # Entity models: build description index
            if entity_models:
                entity_field_texts = []
                entity_field_index = []
                
                for entity_name, entity_df in entity_models.items():
                    # Find description column
                    desc_col = None
                    source_col = None
                    
                    for col in entity_df.columns:
                        if 'desc' in col.lower():
                            desc_col = col
                        if 'source' in col.lower() and 'field' in col.lower():
                            source_col = col
                    
                    if desc_col and source_col:
                        for _, row in entity_df.iterrows():
                            field_name = safe_get(row, source_col, '')
                            field_desc = safe_get(row, desc_col, '')
                            if field_name or field_desc:
                                # E5 passage prefix
                                combined = f"passage: {field_name} {field_desc}".strip()
                                entity_field_texts.append(combined)
                                entity_field_index.append({
                                    'entity': entity_name,
                                    'field_name': field_name,
                                    'description': field_desc
                                })
                
                if entity_field_texts:
                    with torch.cuda.amp.autocast() if torch.cuda.is_available() else torch.no_grad():
                        entity_emb = model.encode(
                            entity_field_texts,
                            batch_size=64,
                            show_progress_bar=True,
                            convert_to_numpy=True,
                            normalize_embeddings=True
                        )
                    st.success(f"‚úÖ Entity descriptions loaded ({len(entity_field_texts)} fields)")
            
            st.success("‚úÖ All embeddings ready (multilingual-e5-large)")
            
            # Clear GPU cache
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Embedding failed: {e}")
            sei_emb_name = None
    
    # Match each SEI field
    results = []
    progress = st.progress(0)
    status = st.empty()
    
    total = len(sei_df)
    matched = 0
    
    for idx, (_, sei_row) in enumerate(sei_df.iterrows()):
        if idx % 50 == 0:
            progress.progress((idx + 1) / total)
            status.text(f"Processing {idx + 1}/{total}... ({matched} matched)")
        
        sei_field = safe_get(sei_row, 'field_name', '')
        sei_desc = safe_get(sei_row, 'field_description', '')
        sei_norm = normalize_text(sei_field)
        
        best_idx = None
        best_score = 0
        best_match_type = ""
        
        # Find best match in AddVantage
        for aidx, (_, addv_row) in enumerate(addv_df.iterrows()):
            addv_field = safe_get(addv_row, 'field_name', '')
            addv_norm = normalize_text(addv_field)
            
            score = 0
            match_type = ""
            
            # 1. Exact field name match (HIGHEST PRIORITY)
            if sei_norm == addv_norm:
                score = 100
                match_type = "Exact name"
            
            # 2. Partial field name match (STRICTER - avoid false positives)
            # Only match if SEI field is the END of AddV field (suffix match)
            # Example: "ACCOUNT_NUMBER" matches "RECEIVING_ACCOUNT_NUMBER" ‚ùå NO
            # Example: "ACCOUNT" matches "ACCOUNT_NUMBER" ‚ùå NO  
            # Example: "NUMBER" matches "ACCOUNT_NUMBER" ‚úÖ YES (suffix)
            elif not score and (addv_norm.endswith(sei_norm) or sei_norm.endswith(addv_norm)):
                # Check it's a meaningful match (not just 1-2 chars)
                if len(sei_norm) >= 3 and len(addv_norm) >= 3:
                    score = 75
                    match_type = "Partial name (suffix)"
            
            # 3. Semantic match using field name only (E5-optimized thresholds)
            if not score and use_semantic and sei_emb_name is not None:
                try:
                    sim_name = np.dot(sei_emb_name[idx], addv_emb[aidx])
                    # E5 produces better similarities - adjusted thresholds
                    if sim_name >= 0.80:  # Was 0.85
                        score = max(score, 90)
                        match_type = "Semantic name (high)"
                    elif sim_name >= 0.70:  # Was 0.75
                        score = max(score, 75)
                        match_type = "Semantic name (med)"
                    elif sim_name >= 0.60:  # Was 0.65
                        score = max(score, 65)
                        match_type = "Semantic name (low)"
                except:
                    pass
            
            # 4. Enhanced semantic match using field name + description (E5-optimized)
            # BUT: Never override exact name matches (score 100)
            if score < 100 and use_semantic and sei_emb_desc is not None and sei_desc:
                try:
                    sim_desc = np.dot(sei_emb_desc[idx], addv_emb[aidx])
                    
                    # E5-optimized thresholds for description matching
                    if sim_desc >= 0.75:  # Was 0.80
                        boost_score = 95
                        if boost_score > score:
                            score = boost_score
                            match_type = "Semantic desc (high)"
                    elif sim_desc >= 0.65:  # Was 0.70
                        boost_score = 85
                        if boost_score > score:
                            score = boost_score
                            match_type = "Semantic desc (med)"
                    elif sim_desc >= 0.55:  # Was 0.60
                        boost_score = 70
                        if boost_score > score:
                            score = boost_score
                            match_type = "Semantic desc (low)"
                except:
                    pass
            
            if score > best_score:
                best_score = score
                best_idx = aidx
                best_match_type = match_type
        
        # Build result - KEEP ALL
        row = sei_row.to_dict()
        
        if best_idx is not None and best_score >= min_score:
            matched += 1
            addv_match = addv_df.iloc[best_idx]
            addv_field_name = safe_get(addv_match, 'field_name')
            
            # Get AddVantage field description from entity model
            # CRITICAL: Use EXACT match only to avoid getting wrong description
            addv_field_desc = ''
            matched_entity_name = ''
            if entity_models and addv_field_name:
                for entity_name, entity_df in entity_models.items():
                    source_col = None
                    desc_col = None
                    
                    for col in entity_df.columns:
                        col_lower = col.lower()
                        if not source_col and 'source' in col_lower and 'field' in col_lower:
                            source_col = col
                        if not desc_col and col_lower == 'field_description':
                            desc_col = col
                    
                    if source_col and desc_col:
                        for _, entity_row in entity_df.iterrows():
                            entity_field = safe_get(entity_row, source_col, '')
                            # EXACT MATCH ONLY - no partial matching to avoid wrong descriptions
                            if entity_field and normalize_text(entity_field) == normalize_text(addv_field_name):
                                addv_field_desc = safe_get(entity_row, desc_col, '')
                                matched_entity_name = entity_name
                                if addv_field_desc:
                                    break
                    
                    if addv_field_desc:
                        break
            
            row['matched_addv_field'] = addv_field_name
            row['matched_addv_description'] = addv_field_desc
            row['matched_addv_file'] = safe_get(addv_match, 'file_clean')
            row['matched_addv_type'] = safe_get(addv_match, 'data_type')
            row['matched_addv_length'] = safe_get(addv_match, 'max_length')
            row['match_score'] = best_score
            row['match_type'] = best_match_type
            row['match_confidence'] = 'High' if best_score >= 85 else 'Medium' if best_score >= 70 else 'Low'
        else:
            # Unmatched - keep with empty values
            row['matched_addv_field'] = ''
            row['matched_addv_description'] = ''
            row['matched_addv_file'] = ''
            row['matched_addv_type'] = ''
            row['matched_addv_length'] = ''
            row['match_score'] = 0
            row['match_type'] = 'No match'
            row['match_confidence'] = 'Unmatched'
        
        results.append(row)
    
    progress.empty()
    status.empty()
    
    result_df = pd.DataFrame(results)
    
    unmatched = total - matched
    
    st.success(f"""
    ‚úÖ **SEI ‚Üí AddVantage Matching Complete!**
    
    Total SEI Fields: {total}
    Matched: {matched} ({matched/total*100:.1f}%)
    Unmatched: {unmatched} ({unmatched/total*100:.1f}%)
    
    ‚ö†Ô∏è All {total} fields kept in results (matched + unmatched)
    """)
    
    return result_df

# ========================================================
# VISUALIZATION
# ========================================================

def create_sei_lineage_diagram(sei_matched_df, selected_interface=None):
    """
    Visual lineage: SEI Field ‚Üí AddVantage Field
    """
    
    if not PLOTLY_AVAILABLE:
        return None
    
    try:
        # Filter by interface if specified
        if selected_interface:
            df = sei_matched_df[sei_matched_df.get('interface_name', '') == selected_interface]
        else:
            df = sei_matched_df.head(15)
        
        if len(df) == 0:
            return None
        
        fig = go.Figure()
        
        num = min(len(df), 15)
        
        for idx, (_, row) in enumerate(df.head(15).iterrows()):
            sei_field = safe_get(row, 'field_name', f'Field_{idx}')
            sei_type = safe_get(row, 'data_type', '')
            addv_field = safe_get(row, 'matched_addv_field', '')
            addv_file = safe_get(row, 'matched_addv_file', '')
            addv_type = safe_get(row, 'matched_addv_type', '')
            confidence = safe_get(row, 'match_confidence', 'Unmatched')
            
            y = 15 - idx
            
            # SEI Field (left)
            fig.add_trace(go.Scatter(
                x=[0], y=[y],
                mode='markers+text',
                marker=dict(size=35, color='#FF6B6B', line=dict(width=2, color='white')),
                text=[sei_field[:25]],
                textposition="middle left",
                textfont=dict(size=9),
                hovertext=f"<b>SEI Field:</b> {sei_field}<br><b>Type:</b> {sei_type}",
                showlegend=False
            ))
            
            # AddVantage Field (right)
            if addv_field:
                color = '#4CAF50' if confidence == 'High' else '#FFC107' if confidence == 'Medium' else '#FF9800'
                
                fig.add_trace(go.Scatter(
                    x=[2], y=[y],
                    mode='markers+text',
                    marker=dict(size=35, color=color, line=dict(width=2, color='white')),
                    text=[addv_field[:25]],
                    textposition="middle right",
                    textfont=dict(size=9),
                    hovertext=f"<b>AddVantage:</b> {addv_field}<br><b>File:</b> {addv_file}<br><b>Type:</b> {addv_type}<br><b>Confidence:</b> {confidence}",
                    showlegend=False
                ))
                
                # Arrow
                fig.add_annotation(
                    x=0.15, y=y, ax=1.85, ay=y,
                    showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=2, arrowcolor=color
                )
            else:
                # No match
                fig.add_trace(go.Scatter(
                    x=[2], y=[y],
                    mode='markers+text',
                    marker=dict(size=30, color='#E0E0E0', line=dict(width=2, color='white')),
                    text=['No Match'],
                    textposition="middle right",
                    textfont=dict(size=8, color='#999'),
                    hovertext="<b>No AddVantage match found</b>",
                    showlegend=False
                ))
                
                # Dotted arrow
                fig.add_annotation(
                    x=0.15, y=y, ax=1.85, ay=y,
                    showarrow=True, arrowhead=1, arrowsize=1, arrowwidth=1, 
                    arrowcolor='#CCC', opacity=0.5
                )
        
        title = f"üîÑ SEI ‚Üí AddVantage: {selected_interface}" if selected_interface else "üîÑ SEI ‚Üí AddVantage (First 15)"
        
        fig.update_layout(
            title=title,
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-0.8, 2.8]),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=max(500, num * 45),
            margin=dict(l=250, r=250, t=60, b=20),
            plot_bgcolor='white'
        )
        
        return fig
        
    except Exception as e:
        st.error(f"Error creating diagram: {e}")
        return None

# ========================================================
# ENHANCED SEI FIELD MAPPING VIEWER
# ========================================================

def render_sei_field_mapping_viewer(matched_df):
    """
    Enhanced SEI Field Mapping Viewer (like AddVantage viewer)
    
    Shows:
    - Overview with metrics
    - Field Details with filters
    - By Interface breakdown
    - Search functionality
    - Match type and descriptions for easy review
    """
    
    if matched_df is None or len(matched_df) == 0:
        st.warning("‚ö†Ô∏è No SEI mappings loaded")
        return
    
    st.markdown("## üìä SEI Field Mapping Viewer")
    
    # Tabs for different views
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Overview", "üîç Field Details", "üìã By Interface", "üîé Search"])
    
    with tab1:
        st.subheader("SEI Mapping Overview")
        
        # Metrics
        col1, col2, col3, col4 = st.columns(4)
        
        total_fields = len(matched_df)
        matched_fields = len(matched_df[matched_df['match_confidence'] != 'Unmatched'])
        unmatched_fields = total_fields - matched_fields
        total_interfaces = matched_df['interface_name'].nunique() if 'interface_name' in matched_df.columns else 0
        
        with col1:
            st.metric("Total SEI Fields", total_fields)
        with col2:
            st.metric("Matched", matched_fields, f"{matched_fields/total_fields*100:.1f}%")
        with col3:
            st.metric("Unmatched", unmatched_fields, f"{unmatched_fields/total_fields*100:.1f}%")
        with col4:
            st.metric("Interfaces", total_interfaces)
        
        st.markdown("---")
        
        # Match confidence breakdown
        st.subheader("Match Confidence Distribution")
        
        confidence_counts = matched_df['match_confidence'].value_counts()
        
        col1, col2 = st.columns(2)
        
        with col1:
            for conf, count in confidence_counts.items():
                pct = count / total_fields * 100
                if conf == 'High':
                    st.success(f"üü¢ **High Confidence:** {count} ({pct:.1f}%)")
                elif conf == 'Medium':
                    st.warning(f"üü° **Medium Confidence:** {count} ({pct:.1f}%)")
                elif conf == 'Low':
                    st.info(f"üü† **Low Confidence:** {count} ({pct:.1f}%)")
                else:
                    st.error(f"‚ö´ **Unmatched:** {count} ({pct:.1f}%)")
        
        with col2:
            # Match type breakdown
            if 'match_type' in matched_df.columns:
                st.subheader("Match Type Breakdown")
                match_types = matched_df[matched_df['match_type'] != 'No match']['match_type'].value_counts()
                for mtype, count in match_types.head(10).items():
                    st.write(f"**{mtype}**: {count} fields")
        
        st.markdown("---")
        
        # Interface distribution
        if 'interface_name' in matched_df.columns:
            st.subheader("Fields by Interface")
            interface_counts = matched_df['interface_name'].value_counts().head(10)
            for interface, count in interface_counts.items():
                st.write(f"üìÑ **{interface}**: {count} fields")
    
    with tab2:
        st.subheader("Complete Field Details")
        
        # Filter options
        col1, col2, col3 = st.columns(3)
        
        with col1:
            show_filter = st.selectbox(
                "Show:",
                ["All Fields", "Matched Only", "Unmatched Only", "High Confidence", "Medium Confidence", "Low Confidence"],
                key="sei_show_filter"
            )
        
        with col2:
            if 'interface_name' in matched_df.columns:
                interfaces = ["All Interfaces"] + sorted(matched_df['interface_name'].unique().tolist())
                selected_interface = st.selectbox("Filter by Interface:", interfaces, key="sei_interface_filter")
            else:
                selected_interface = "All Interfaces"
        
        with col3:
            if 'match_type' in matched_df.columns:
                match_types = ["All Types"] + sorted(matched_df[matched_df['match_type'] != 'No match']['match_type'].unique().tolist())
                selected_type = st.selectbox("Filter by Match Type:", match_types, key="sei_match_type_filter")
            else:
                selected_type = "All Types"
        
        # Apply filters
        filtered_df = matched_df.copy()
        
        if show_filter == "Matched Only":
            filtered_df = filtered_df[filtered_df['match_confidence'] != 'Unmatched']
        elif show_filter == "Unmatched Only":
            filtered_df = filtered_df[filtered_df['match_confidence'] == 'Unmatched']
        elif show_filter in ['High Confidence', 'Medium Confidence', 'Low Confidence']:
            conf = show_filter.replace(' Confidence', '')
            filtered_df = filtered_df[filtered_df['match_confidence'] == conf]
        
        if selected_interface != "All Interfaces":
            filtered_df = filtered_df[filtered_df['interface_name'] == selected_interface]
        
        if selected_type != "All Types":
            filtered_df = filtered_df[filtered_df['match_type'] == selected_type]
        
        st.write(f"Showing {len(filtered_df)} of {len(matched_df)} fields")
        
        # Display columns - enhanced with descriptions
        display_cols = [
            'interface_name',  # Feed name (entity)
            'field_name',  # SEI field
            'field_description',  # SEI description
            'data_type',  # SEI data type
            'matched_addv_field',  # AddVantage field
            'matched_addv_description',  # AddVantage description from entity
            'matched_addv_file',  # AddVantage file
            'matched_addv_type',  # AddVantage type
            'match_score',  # Score
            'match_type',  # How it matched
            'match_confidence',  # Confidence level
            'entity_suggestion'  # Entity cross-reference
        ]
        
        display_cols = [col for col in display_cols if col in filtered_df.columns]
        
        # Rename columns for clarity
        display_df = filtered_df[display_cols].copy()
        rename_map = {
            'interface_name': 'SEI Interface (Feed)',
            'field_name': 'SEI Field',
            'field_description': 'SEI Description',
            'data_type': 'SEI Type',
            'matched_addv_field': 'AddVantage Field',
            'matched_addv_description': 'AddVantage Description',
            'matched_addv_file': 'AddVantage File',
            'matched_addv_type': 'AddV Type',
            'match_score': 'Score',
            'match_type': 'Match Method',
            'match_confidence': 'Confidence',
            'entity_suggestion': 'Entity Reference'
        }
        display_df = display_df.rename(columns={k: v for k, v in rename_map.items() if k in display_df.columns})
        
        st.dataframe(
            display_df,
            use_container_width=True,
            height=500
        )
        
        # Export
        csv = filtered_df.to_csv(index=False)
        st.download_button(
            "üì• Export Filtered Data",
            csv,
            "sei_mappings_filtered.csv",
            "text/csv"
        )
    
    with tab3:
        st.subheader("Field Mapping by Interface")
        
        if 'interface_name' not in matched_df.columns:
            st.warning("Interface name column not found")
            return
        
        interface_list = sorted(matched_df['interface_name'].unique())
        selected_interface_viz = st.selectbox(
            "Select Interface to Visualize:",
            interface_list,
            key="interface_viz_select"
        )
        
        if selected_interface_viz:
            interface_data = matched_df[matched_df['interface_name'] == selected_interface_viz]
            
            st.write(f"**Interface:** {selected_interface_viz}")
            st.write(f"**Total Fields:** {len(interface_data)}")
            st.write(f"**Matched:** {len(interface_data[interface_data['match_confidence'] != 'Unmatched'])}")
            
            # Lineage diagram
            lineage_fig = create_sei_lineage_diagram(matched_df, selected_interface_viz)
            if lineage_fig:
                st.plotly_chart(lineage_fig, use_container_width=True)
            
            st.markdown("---")
            
            # Field table for this interface with descriptions
            st.subheader(f"All Fields in {selected_interface_viz}")
            
            interface_display_cols = [
                'field_name',
                'field_description',
                'matched_addv_field',
                'matched_addv_description',
                'matched_addv_file',
                'match_score',
                'match_type',
                'match_confidence'
            ]
            interface_display_cols = [c for c in interface_display_cols if c in interface_data.columns]
            
            st.dataframe(
                interface_data[interface_display_cols],
                use_container_width=True
            )
    
    with tab4:
        st.subheader("üîé Search Fields")
        
        search_term = st.text_input("Search for field name or description:", key="sei_search")
        
        search_in = st.radio(
            "Search in:",
            ["SEI Field Names", "SEI Descriptions", "AddVantage Fields", "All"],
            horizontal=True,
            key="sei_search_in"
        )
        
        if search_term:
            search_lower = search_term.lower()
            
            mask = pd.Series([False] * len(matched_df))
            
            if search_in in ["SEI Field Names", "All"]:
                mask |= matched_df['field_name'].str.lower().str.contains(search_lower, na=False)
            
            if search_in in ["SEI Descriptions", "All"] and 'field_description' in matched_df.columns:
                mask |= matched_df['field_description'].str.lower().str.contains(search_lower, na=False)
            
            if search_in in ["AddVantage Fields", "All"]:
                mask |= matched_df['matched_addv_field'].str.lower().str.contains(search_lower, na=False)
            
            results = matched_df[mask]
            
            if len(results) > 0:
                st.success(f"‚úÖ Found {len(results)} matches")
                
                # Show with descriptions
                search_display_cols = [
                    'interface_name',
                    'field_name',
                    'field_description',
                    'matched_addv_field',
                    'matched_addv_description',
                    'matched_addv_file',
                    'match_score',
                    'match_type',
                    'match_confidence'
                ]
                search_display_cols = [c for c in search_display_cols if c in results.columns]
                
                st.dataframe(
                    results[search_display_cols],
                    use_container_width=True
                )
            else:
                st.info(f"No matches found for '{search_term}'")

# ========================================================
# MAIN UI
# ========================================================

def main():
    st.title("üîÑ Complete Field Mapping Tool")
    
    st.markdown("""
    **Map multiple sources to AddVantage:**
    - Entity Models ‚Üí AddVantage
    - SEI System ‚Üí AddVantage
    """)
    
    # SIDEBAR
    with st.sidebar:
        st.header("üìÇ File Uploads")
        
        # 1. Entity Models
        st.markdown("### üìä Entity Model Reference")
        entity_file = st.file_uploader("Upload Entity Model", type=['xlsx', 'xls'], key="entity")
        
        if entity_file and not st.session_state.entity_models:
            with st.spinner("Loading..."):
                matrix, models = ee.load_entity_model_reference(entity_file)
                if matrix is not None:
                    st.session_state.entity_matrix_df = matrix
                    st.session_state.entity_models = models
                    st.success(f"‚úÖ {len(models)} entities")
        
        # 2. AddVantage
        st.markdown("---")
        st.markdown("### üìÅ AddVantage Fields")
        st.caption("Sheet: 'Metadata' (or first sheet)")
        addv_file = st.file_uploader("Upload AddVantage", type=['xlsx', 'xls'], key="addv")
        
        if addv_file and st.session_state.addvantage_df is None:
            with st.spinner("Loading..."):
                # Use first sheet (which should be Metadata)
                addv_df = fmv.load_addvantage_field_mapping(addv_file)
                if addv_df is not None:
                    st.session_state.addvantage_df = addv_df
                    st.success(f"‚úÖ {len(addv_df)} fields")
        
        # 3. SEI
        st.markdown("---")
        st.markdown("### üìä SEI System")
        st.caption("Sheet: 'All Feeds'")
        sei_file = st.file_uploader("Upload SEI Mapping", type=['xlsx', 'xls'], key="sei")
        
        if sei_file and st.session_state.sei_df is None:
            with st.spinner("Loading..."):
                sei_df = load_sei_mapping(sei_file)
                if sei_df is not None:
                    st.session_state.sei_df = sei_df
                    st.success(f"‚úÖ {len(sei_df)} fields")
        
        # MATCHING
        st.markdown("---")
        st.markdown("### üîÑ Matching Options")
        
        use_semantic = st.checkbox("Enable AI Semantic Matching", value=True)
        min_score = st.slider("Minimum Match Score", 30, 100, 60)
        
        # Entity ‚Üí AddVantage
        if st.session_state.entity_models and st.session_state.addvantage_df is not None:
            if st.button("‚ñ∂Ô∏è Match Entity ‚Üí AddVantage", type="primary"):
                with st.spinner("Matching..."):
                    result = fmv.match_fields_to_entity_models(
                        st.session_state.addvantage_df,
                        st.session_state.entity_models,
                        min_score=min_score,
                        use_semantic=use_semantic
                    )
                    if result is not None:
                        st.session_state.matched_entity_addv = result
                        st.success("‚úÖ Done!")
                        st.rerun()
        
        # SEI ‚Üí AddVantage
        if st.session_state.sei_df is not None and st.session_state.addvantage_df is not None:
            if st.button("‚ñ∂Ô∏è Match SEI ‚Üí AddVantage", type="primary"):
                with st.spinner("Matching..."):
                    result = match_sei_to_addvantage(
                        st.session_state.sei_df,
                        st.session_state.addvantage_df,
                        entity_models=st.session_state.entity_models if st.session_state.entity_models else None,
                        min_score=min_score,
                        use_semantic=use_semantic
                    )
                    if result is not None:
                        st.session_state.matched_sei_addv = result
                        st.success("‚úÖ Done!")
                        st.rerun()
        
        # Clear
        st.sidebar.markdown("---")
        
        # Build Complete Lineage button
        if (st.session_state.matched_sei_addv is not None and 
            st.session_state.matched_entity_addv is not None and 
            st.session_state.entity_models):
            
            st.sidebar.markdown("### üîÑ Complete Lineage")
            if st.sidebar.button("üîó Build SEI ‚Üí AddV ‚Üí Entity", type="primary"):
                with st.spinner("Building complete end-to-end lineage..."):
                    complete_lineage = clv.build_complete_lineage(
                        st.session_state.matched_sei_addv,
                        st.session_state.matched_entity_addv,
                        st.session_state.entity_models
                    )
                    if complete_lineage is not None:
                        st.session_state.complete_lineage_df = complete_lineage
                        st.sidebar.success("‚úÖ Complete lineage built!")
                        st.rerun()
        
        st.sidebar.markdown("---")
        if st.button("üóëÔ∏è Clear All Data"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
    
    # MAIN TABS
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Entity Models",
        "üìÅ AddVantage Fields",
        "üìä SEI Mapping",
        "üîÑ Complete Lineage",
        "üìã Summary"
    ])
    
    with tab1:
        st.subheader("Entity Model Explorer")
        
        if st.session_state.entity_models and st.session_state.entity_matrix_df is not None:
            # Use full entity explorer with ERD
            ee.render_entity_explorer(
                st.session_state.entity_matrix_df,
                st.session_state.entity_models
            )
        elif st.session_state.entity_models:
            # Fallback if no matrix
            st.info("Entity models loaded. Upload complete Entity Model Reference for full features.")
            entity_list = sorted(st.session_state.entity_models.keys())
            
            selected = st.selectbox(
                "Select Entity:",
                ["-- Choose Entity --"] + entity_list,
                key="entity_select_fallback"
            )
            
            if selected and selected != "-- Choose Entity --":
                entity_df = st.session_state.entity_models[selected]
                st.markdown(f"### {selected}")
                st.write(f"**Fields:** {len(entity_df)}")
                st.dataframe(entity_df, use_container_width=True, height=400)
                
                # Export
                csv = entity_df.to_csv(index=False)
                st.download_button(
                    "üì• Export CSV",
                    csv,
                    f"{selected}_fields.csv",
                    "text/csv",
                    key="entity_export_fallback"
                )
        else:
            st.info("üëà Upload Entity Model Reference in sidebar")
    
    with tab2:
        st.subheader("AddVantage Field Mapping")
        
        if st.session_state.matched_entity_addv is not None:
            fmv.render_field_mapping_viewer(st.session_state.matched_entity_addv)
        elif st.session_state.addvantage_df is not None:
            st.info("‚úÖ AddVantage fields loaded. Click 'Match Entity ‚Üí AddVantage' in sidebar.")
            st.dataframe(st.session_state.addvantage_df.head(20))
        else:
            st.info("üëà Upload AddVantage field mapping in sidebar")
    
    with tab3:
        st.subheader("üìä SEI Mapping")
        
        if st.session_state.matched_sei_addv is not None:
            # Use enhanced viewer
            render_sei_field_mapping_viewer(st.session_state.matched_sei_addv)
        elif st.session_state.sei_df is not None:
            st.info("‚úÖ SEI fields loaded. Click 'Match SEI ‚Üí AddVantage' in sidebar.")
            
            # Show preview with descriptions
            st.markdown("### Preview of SEI Data")
            preview_cols = ['interface_name', 'field_name', 'field_description', 'data_type']
            preview_cols = [c for c in preview_cols if c in st.session_state.sei_df.columns]
            st.dataframe(st.session_state.sei_df[preview_cols].head(20), use_container_width=True)
        else:
            st.info("üëà Upload SEI mapping in sidebar")
    
    with tab4:
        st.subheader("üîÑ Complete End-to-End Lineage")
        st.markdown("### SEI ‚Üí AddVantage ‚Üí Entity (DWH)")
        
        if st.session_state.complete_lineage_df is not None:
            # Render complete lineage viewer
            clv.render_complete_lineage_viewer(st.session_state.complete_lineage_df)
        else:
            st.info("üëà Click 'Build SEI ‚Üí AddV ‚Üí Entity' in sidebar")
            
            st.markdown("""
            ### üîÑ Complete Data Lineage
            
            This view shows the **complete end-to-end lineage**:
            
            ```
            SEI Field ‚Üí AddVantage Field ‚Üí Entity DWH Field
            ```
            
            **What you'll see:**
            - SEI field names and descriptions
            - Matched AddVantage fields
            - Entity source fields and descriptions
            - Entity DWH columns (final destination)
            - Match quality at each step
            - Complete traceability
            
            **To build:**
            1. Match Entity ‚Üí AddVantage
            2. Match SEI ‚Üí AddVantage
            3. Click "Build SEI ‚Üí AddV ‚Üí Entity" in sidebar
            """)
            
            # Show prerequisites
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.session_state.matched_entity_addv is not None:
                    st.success("‚úÖ Entity ‚Üí AddV matched")
                else:
                    st.warning("‚ö†Ô∏è Need: Entity ‚Üí AddV match")
            
            with col2:
                if st.session_state.matched_sei_addv is not None:
                    st.success("‚úÖ SEI ‚Üí AddV matched")
                else:
                    st.warning("‚ö†Ô∏è Need: SEI ‚Üí AddV match")
            
            with col3:
                if st.session_state.entity_models:
                    st.success("‚úÖ Entity models loaded")
                else:
                    st.warning("‚ö†Ô∏è Need: Entity models")
    
    with tab5:
        st.subheader("üìã Mapping Summary")
        
        # Show status of all mappings
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### Entity ‚Üí AddVantage")
            if st.session_state.matched_entity_addv is not None:
                df = st.session_state.matched_entity_addv
                total = len(df)
                matched = len(df[df['match_confidence'] != 'Unmatched'])
                
                st.success(f"‚úÖ Matched: {matched}/{total} ({matched/total*100:.1f}%)")
                
                # Coverage by entity
                if 'matched_entity' in df.columns:
                    coverage = df[df['match_confidence'] != 'Unmatched']['matched_entity'].value_counts()
                    st.write("**Top Entities:**")
                    for entity, count in coverage.head(5).items():
                        st.write(f"- {entity}: {count} fields")
            else:
                st.info("Not yet matched")
        
        with col2:
            st.markdown("### SEI ‚Üí AddVantage")
            if st.session_state.matched_sei_addv is not None:
                df = st.session_state.matched_sei_addv
                total = len(df)
                matched = len(df[df['match_confidence'] != 'Unmatched'])
                
                st.success(f"‚úÖ Matched: {matched}/{total} ({matched/total*100:.1f}%)")
                
                # Coverage by interface
                if 'interface_name' in df.columns:
                    interface_matched = df[df['match_confidence'] != 'Unmatched']['interface_name'].value_counts()
                    st.write("**Top Interfaces:**")
                    for interface, count in interface_matched.head(5).items():
                        st.write(f"- {interface}: {count} fields")
            else:
                st.info("Not yet matched")

if __name__ == "__main__":
    main()
